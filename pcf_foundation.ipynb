{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to process pcfusage.sh script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "##########################################################\n",
    "# Looking to build more interactive dashboard\n",
    "# TODO: Allow interactive analysis and report generation\n",
    "##########################################################\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "##########################################################\n",
    "# Sample files capture by the pcfusage.sh script\n",
    "# TODO: Add this information in a metadata section\n",
    "# NOTE: Make sure the capture_date is expressed in the same\n",
    "#       timezone as the foundation on which this script was\n",
    "#       run or your application ages won't be correct.\n",
    "##########################################################\n",
    "\n",
    "# BORGESCLOUD File\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/dev_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 6, 26, 0, 0)\n",
    "# diego_cell = {\"number_of\": 4, \"vcpu\": 4, \"ram_gb\": 32, \"disk_gb\": 32 }\n",
    "\n",
    "# Sample 1\n",
    "# file = \"/Users/mborges/Tools/PCF/scripts/samples/sample1_foundation.json\"\n",
    "# capture_date = datetime.datetime(2018, 7, 2, 22, 0)\n",
    "# diego_cell = {\"number_of\": 8, \"vcpu\": 8, \"ram_gb\": 32, \"disk_gb\": 256 }\n",
    "\n",
    "# Sample 2\n",
    "file = \"/Users/bthelen/workspace/pcf-usage/coronado_foundation.json\"\n",
    "capture_date = datetime.datetime(2018, 7, 20, 16, 0)\n",
    "diego_cell = {\"number_of\": 16, \"vcpu\": 4, \"ram_gb\": 32, \"disk_gb\": 128 }\n",
    "\n",
    "##########################################################\n",
    "# Pre-processing of the foundation.json file\n",
    "##########################################################\n",
    "\n",
    "# Know system orgs we used to remove system applications from our analysis\n",
    "system_orgs = [\"system\", \"p-dataflow\", \"p-spring-cloud-services\"]\n",
    "\n",
    "# Foundation capacity from metadata section (currently data above)\n",
    "total_vcpu = diego_cell['number_of'] * diego_cell['vcpu']\n",
    "total_memory = diego_cell['number_of'] * diego_cell['ram_gb']\n",
    "\n",
    "# Foundation json capture via script\n",
    "with open(file, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "    \n",
    "# Creating dataframes for specific sections\n",
    "# TODO: Can we not rely on the index? \n",
    "df_apps = pd.DataFrame(data[0][\"apps\"])\n",
    "df_orgs = pd.DataFrame(data[1][\"orgs\"])\n",
    "df_service_instances = pd.DataFrame(data[2][\"service_instances\"])\n",
    "df_services = pd.DataFrame(data[3][\"services\"])\n",
    "df_spaces = pd.DataFrame(data[4][\"spaces\"])\n",
    "df_users = pd.DataFrame(data[5][\"users\"])\n",
    "\n",
    "# Fix column names so we can merge\n",
    "# TODO: Look inot fixing the pcfusage.sh script so this is not longer need\n",
    "df_orgs = df_orgs.rename(columns = {\"name\":\"org\"})\n",
    "df_spaces = df_spaces.rename(columns = {\"name\": \"space\", \"org\":\"org_guid\"})\n",
    "df_apps = df_apps.rename(columns = {\"space\": \"space_guid\"})\n",
    "\n",
    "# Merge spaces and orgs and create an non_system_spaces series\n",
    "environments = pd.merge(df_spaces, df_orgs, on=\"org_guid\")\n",
    "non_system_spaces = (environments['org'].isin(system_orgs))\n",
    "\n",
    "# Merge apps with spaces to get org and space names\n",
    "apps = pd.merge(df_apps, environments, on=\"space_guid\")\n",
    "\n",
    "# Merge services with service instances\n",
    "services = pd.merge(df_services, df_service_instances, on=\"service_guid\")\n",
    "\n",
    "# Non system applications\n",
    "#non_system_apps = (apps['org'] != 'system') & (apps['org'] != 'p-dataflow')\n",
    "system_apps = apps['org'].isin(system_orgs)\n",
    "non_system_apps = ~apps['org'].isin(system_orgs)\n",
    "\n",
    "# This is the core dataframe for applications\n",
    "df_non_system_apps = apps[non_system_apps]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundation by Numbers\n",
    "## speed\n",
    "Organizations can represent different business units, spaces environments where initial setup lead and process time are usually high. Services and buildpacks represents the middleware required to develop applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Orgs: {}\".format(len(df_non_system_apps['org'].unique())))\n",
    "print (\"Spaces: {}\".format(len(df_non_system_apps['space'].unique())))\n",
    "print (\"Users: {}\".format(len(list(df_users))))\n",
    "print (\"Services: {}\".format(len(df_services['label'].unique())))\n",
    "print (\"Unique Applications: {}\".format(len(df_non_system_apps['name'].unique())))\n",
    "print (\"Buildpacks: {}\".format(len(df_non_system_apps['buildpack'].unique())))\n",
    "print (\"Containers: {}\".format(df_non_system_apps['instances'].sum()))\n",
    "print (\"Service Instances: {}\".format(len(df_service_instances['name'].unique())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Instance Memory in MB\n",
    "## scalability\n",
    "Statistics on memory usage by all customer applications. This can show scalability of PCF by comparing min and max memory sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_system_apps['memory'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density\n",
    "## savings\n",
    "Number of containers per CPU and per vCPU. This can show infrastructure consolidation and savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers_per_cell = apps[non_system_apps]['instances'].sum() / diego_cell['number_of']\n",
    "containers_per_vcpu = apps[non_system_apps]['instances'].sum() / total_vcpu\n",
    "print (\"Total system apps: {} and non system apps: {}\".format(apps[system_apps]['instances'].sum(), apps[non_system_apps]['instances'].sum()))\n",
    "print (\"containers_per_cell of non system apps {}\".format(containers_per_cell))\n",
    "print (\"containers_per_vcpu of non system apps {}\".format(containers_per_vcpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application per Orgs\n",
    "This could provide a view into the different business units on the platform based on the nomenclature used. The more BUs the more compound value the platform can bring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "#orgs = apps.groupby(\"org\").size()\n",
    "orgs = apps[non_system_apps].groupby(\"org\").size()\n",
    "orgs.plot.barh(figsize=(5,5))\n",
    "print(orgs)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Applications', fontsize=16)\n",
    "plt.ylabel('Organizations', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apps per Environments (Spaces)\n",
    "Spaces can be analagous to environments and based on the nomenclature there is a lot that can be inferred in a value analysis. Consistency between environments (buildpacks / rootfs), improved CI/CD (easier deployment commands across consisten environments), developer velociy with safety in mind (patch, upgrades, updates). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces = apps[non_system_apps].groupby(\"space\").size()\n",
    "spaces.plot.barh(figsize=(5,5))\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Applications', fontsize=16)\n",
    "plt.ylabel('Spaces', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Analysis\n",
    "This is an attempt to create interactive dahsboards so we can better explorer value to various customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apps.head()\n",
    "\n",
    "from ipywidgets import interactive\n",
    " \n",
    "items = ['All']+sorted(apps['org'].unique().tolist())\n",
    " \n",
    "def view(x=''):\n",
    "    if x=='All': \n",
    "        display(apps)\n",
    "    else:\n",
    "        result = apps[apps['org']==x] \n",
    "        print (\"Total Apps: {}\".format(result['instances'].count()))\n",
    "        display(result)\n",
    "\n",
    "w = widgets.Select(options=items)\n",
    "widgets.VBox([widgets.Label('Organizations'), interactive(view, x=w)])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Productivity - Application vs Days\n",
    "## speed\n",
    "Here we explore when was an application last updated comparing with the date the data was capture to infer speed. We should see an increase of deployments due to the automation of the platform. We can possibly measure developer productivity by comparing with how long releases took in the past or testing methodologies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "#d = datetime.datetime.strptime('2018-02-07T03:17:13Z', '%Y-%m-%dT%H:%M:%SZ')\n",
    "def get_days(last_updated):\n",
    "    if last_updated is not None:\n",
    "        deltatime = capture_date - datetime.datetime.strptime(last_updated, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        return deltatime.days\n",
    "    else:\n",
    "        return 999\n",
    "\n",
    "# df_non_system_apps['days'] = df_non_system_apps['updated'].apply(get_days)\n",
    "app_days = df_non_system_apps['updated'].apply(get_days)\n",
    "\n",
    "#app_days.plot.hist(bins=50)\n",
    "N, bins, patches = plt.hist(app_days, 30, ec='k')\n",
    "\n",
    "cmap = plt.get_cmap('jet')\n",
    "hot = cmap(0.9)\n",
    "warm =cmap(0.7)\n",
    "cold = cmap(0.2)\n",
    "\n",
    "for i in range(0,7):\n",
    "    patches[i].set_facecolor(hot)\n",
    "for i in range(7,14):\n",
    "    patches[i].set_facecolor(warm)\n",
    "for i in range(14,30):\n",
    "    patches[i].set_facecolor(cold)\n",
    "\n",
    "#create legend\n",
    "handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [hot,warm, cold]]\n",
    "labels= [\"hot\",\"warm\", \"cold\"]\n",
    "plt.legend(handles, labels)\n",
    "\n",
    "plt.xlabel('Days', fontsize=16)\n",
    "plt.ylabel('Applications', fontsize=16)\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)  \n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_days.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildpack Distribution\n",
    "This provides an few of the languages and frameworks used in the platform. This can be used in regards to saving on middleware license and support. There is also day 2 ops concepts on maintaining current versions and consistently patching across environments. This is usually a subset of the available buildpack on PCF. We can talk about innovation and enabling multi-language for modern microservices based development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_non_system_apps.groupby(\"buildpack\").size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "\n",
    "buildpacks = df_non_system_apps.groupby(\"buildpack\").size()\n",
    "\n",
    "# buildpacks.plot.pie(figsize=(20,20), title=\"Buildpack Distribution\")\n",
    "buildpacks.plot.pie(figsize=(20,20))\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('')\n",
    "\n",
    "# labels = df_apps['buildpack'].unique()\n",
    "\n",
    "# handles = []\n",
    "# for i, l in enumerate(labels):\n",
    "#     handles.append(matplotlib.patches.Patch(color=plt.cm.Set3((i)/8.), label=l))\n",
    "# plt.legend(handles,labels, bbox_to_anchor=(0.85,1.025), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_memory = df_apps[\"memory\"].sum()\n",
    "AI_count = df_apps[\"instances\"].sum()\n",
    "unique_apps = len(apps['name'].unique())\n",
    "\n",
    "print(\"Total Apps is {}\".format(unique_apps))\n",
    "print(\"Total AIs: {} consuming {} MB RAM\".format(AI_count, AI_memory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Services\n",
    "Fast provisioning of data services, platform services like autoscaler, SSO or batch are often not easy to manage. The concept of a marketplace is huge for developer velocity who usually have to wait to get access to RDBMS or messaging systems. A lot of value to explor here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(df_service_instances.groupby(\"service_guid\").size())\n",
    "\n",
    "service_usage = services.groupby('label').size()\n",
    "\n",
    "service_usage.plot.pie(figsize=(10,10))\n",
    "\n",
    "\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
